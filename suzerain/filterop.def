/*--------------------------------------------------------------------------
 *
 * Copyright (C) 2012-2014 The PECOS Development Team
 * Please see http://pecos.ices.utexas.edu for more information on PECOS.
 *
 * This file is part of Suzerain.
 *
 * Suzerain is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * Suzerain is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with Suzerain.  If not, see <http://www.gnu.org/licenses/>.
 *
 *--------------------------------------------------------------------------
 */

/** @file
 * Templated functionality used within filterop.c
 */

// TODO Account for non-banded nature of periodicity (Toeplitz)

// #include-time parameters available followed by a sample usage.
// Each of these are #undef-ed at the end of this template file
//
// #define SCALAR         complex_double   /* Scalar type        */
// #define BLAS(pre,post) pre ## z ## post /* Call BLAS routines */
// #define WORK(pre,post) pre ## z ## post /* e.g. Workspace     */

// Indexing utilities for banded matrices
#ifndef FILTEROP_INTERNAL_ONCE
#define FILTEROP_INTERNAL_ONCE
static inline int imin(int a, int b) { return a < b ? a : b; }
static inline int imax(int a, int b) { return a > b ? a : b; }
#endif /* FILTEROP_INTERNAL_ONCE */

#define STRINGIFY_HELPER(x) #x
#define STRINGIFY(x)        STRINGIFY_HELPER(x)

static int WORK(suzerain_filterop,_operator_bandwidths_cookcabot2005)(
    const SCALAR *method_params,
    int *klat,
    int *kuat,
    int *klbt,
    int *kubt)
{
    SUZERAIN_UNUSED(method_params);
    *klat = *kuat = 2;
    *klbt = *kubt = 4;
    return SUZERAIN_SUCCESS;
}
static int WORK(suzerain_filterop,_operator_bandwidths)(
    const enum suzerain_filterop_method method,
    const SCALAR *method_params,
    int *klat,
    int *kuat,
    int *ldat,
    int *klbt,
    int *kubt,
    int *ldbt)
{
    int retval;

    // Add new method-specific routines here, when necessary
    switch (method) {
    case SUZERAIN_FILTEROP_COOKCABOT2005:
        retval = WORK(suzerain_filterop,_operator_bandwidths_cookcabot2005)(
                    method_params, klat, kuat, klbt, kubt);
        break;
    default:
        SUZERAIN_ERROR_NULL("Unknown method", SUZERAIN_ESANITY);
    }

    assert(*klat >= 0);
    assert(*kuat >= 0);
    assert(*klbt >= 0);
    assert(*kubt >= 0);

    if (retval == SUZERAIN_SUCCESS) {
        *ldat = 2*(*klat) + *kuat + 1; // Preparing for factorization
        *ldbt =    *klbt  + *kubt + 1; // No factorization
    }

    return retval;
}

static int WORK(suzerain_filterop,_operator_assemble_cookcabot2005)(
    const SCALAR *method_params,
    WORK(suzerain_filterop,_workspace) *w)
{
    // Unpack method-specific parameters using defaults whenever NULL
    const SCALAR alpha = method_params ? method_params[0]
                                       : ((SCALAR) 66624)/100000;

    static const int inc = 1;   // Column vectors are contiguous in memory
    const int n = w->n;         // Filtering matrices are square

    // Compute coefficients for CookCabot2005 filter
    // NB: Convince yourself that type promotion gives full SCALAR precision
    const SCALAR alpha_0 = 1;
    const SCALAR alpha_1 = alpha;
    const SCALAR alpha_2 = (  1-    alpha)/  2;
    const SCALAR a_0     = ( 58+105*alpha)/128;
    const SCALAR a_1     = ( 14+ 11*alpha)/ 32;
    const SCALAR a_2     = ( 18- 11*alpha)/ 64;
    const SCALAR a_3     = (  2-  3*alpha)/ 32;
    const SCALAR a_4     = (- 2+  3*alpha)/256;

    // Place nonzero B^T values in w->B_T using w->klbt, w->kubt, and w->ldbt.
    {
        // Banded matrix access has form a[(ku + i)*inc + j*(lda - inc)].
        // Incorporate the ku offset and decrement ld to speed indexing.
        // Further, increment kl anticipating calls like imin(m, j + kl + 1).
        int ku = w->kubt, ld = w->ldbt;
        SCALAR * bt_j = w->B_T;
        bt_j += ku*inc;
        ld -= inc;

        // With the row elements of B_T coded explicitly
        // there is no need for kl+1
        // ++kl;

        assert(w->klbt == 4);
        assert(w->kubt == 4);

        for (int j = 0; j < n; bt_j += ld, ++j) {

            // Start at j - ku, go to j + kl, Bandwidth is 4
            bt_j[(j-4)*inc] = a_4;
            bt_j[(j-3)*inc] = a_3;
            bt_j[(j-2)*inc] = a_2;
            bt_j[(j-1)*inc] = a_1;
            bt_j[(j  )*inc] = a_0;
            bt_j[(j+1)*inc] = a_1;
            bt_j[(j+2)*inc] = a_2;
            bt_j[(j+3)*inc] = a_3;
            bt_j[(j+4)*inc] = a_4;
        }
    }

    // Place nonzero A^T values in w->A_T using w->klat, w->kuat, and w->ldat.
    {
        // Again, access has form a[(ku + i)*inc + j*(lda - inc)].
        int kl = w->klat, ku = w->kuat, ld = w->ldat;
        SCALAR * at_j = w->A_T + kl; // Accounts for factorization-ready data
        at_j += ku*inc;
        ld -= inc;

        // With the row elements of A_T coded explicitly
        // there is no need for kl+1
        // ++kl;

        assert(w->klat == 2);
        assert(w->kuat == 2);

        for (int j = 0; j < n; at_j += ld, ++j) {

            // Start at j - ku, go to j + kl, Bandwidth is 2
            at_j[(j-2)*inc] = alpha_2;
            at_j[(j-1)*inc] = alpha_1;
            at_j[(j  )*inc] = alpha_0;
            at_j[(j+1)*inc] = alpha_1;
            at_j[(j+2)*inc] = alpha_2;
        }
    }

    // Note: The matrices A_T and B_T were populated in
    // BLAS-General-Band storage mode. The following loop
    // would populate elements from a matrix
    // with elements A_T[i,j] = 100*i+j:
    // for (int j = 0; j < n; at_j += ld, ++j) {
    // const int il = imax(0, j - ku), iu = imin(m, j + kl);
    //   for (int i = il; i < iu; ++i) {
    //      at_j[i*inc] =  100*i + j;
    //   }
    // }
    // where kl = w->klat + 1
    // A sample matrix of bandwidth 2 with 7 elements
    // generated with the loop above:
    // const SCALAR good_A_T[] = {
    //     // ku2      ku1     diag      kl1      kl2
    //     -55555,  -55555,       0,     100,     200,
    //     -55555,       1,     101,     201,     301,
    //          2,     102,     202,     302,     402,
    //        103,     203,     303,     403,     503,
    //        204,     304,     404,     504,     604,
    //        305,     405,     505,     605,  -55555,
    //        406,     506,     606,  -55555,  -55555
    // };

    return SUZERAIN_SUCCESS;
}

static int WORK(suzerain_filterop,_operator_assemble)(
    const SCALAR *method_params,
    WORK(suzerain_filterop,_workspace) *w)
{
    int retval;

    // Add new method-specific routines here, when necessary
    switch (w->method) {
    case SUZERAIN_FILTEROP_COOKCABOT2005:
        retval = WORK(suzerain_filterop,_operator_assemble_cookcabot2005)(
                    method_params, w);
        break;
    default:
        SUZERAIN_ERROR_NULL("Unknown method", SUZERAIN_ESANITY);
    }

    return retval;
}

static int WORK(suzerain_filterop,_operator_boundaries)(
    WORK(suzerain_filterop,_workspace) *w)
{
    int retval = SUZERAIN_SUCCESS;
    static const int inc = 1;   // Column vectors are contiguous in memory
    const int n = w->n;         // Filtering matrices are square

    // Add new boundary-type routines here, when necessary
    switch (w->b_first) {
    case SUZERAIN_FILTEROP_BOUNDARY_IGNORE:
        /* Nothing to be done */
        break;

    case SUZERAIN_FILTEROP_BOUNDARY_NOFILTER:
        // Replace near-boundary schemes on B^T
        {
            // Banded matrix access has form a[(ku+i)*inc + j*(lda-inc)].
            // Incorporate the ku offset and decrement ld to speed indexing
            int ku = w->kubt, ld = w->ldbt;
            int nbs = imax(w->kuat, w->kubt); // nbs: near-boundary stencils
            SCALAR * bt_j = w->B_T;
            bt_j += ku*inc;
            ld -= inc;

            for (int j = 0; j < nbs; bt_j += ld, ++j) {

                // Start at j - ku, go down to 1
                for (int joff = w->kubt; joff > 0; --joff) {
                    bt_j[(j-joff)*inc] = 0;
                }
                // Diagonal element
                bt_j[(j  )*inc] = 1;
                // Start at 1, go to j + kl
                for (int joff = 1; joff < w->klbt+1; ++joff) {
                    bt_j[(j+joff)*inc] = 0;
                }
            }
        }

        // Replace near-boundary schemes on A^T
        {
            // Again, access has form a[(ku + i)*inc + j*(lda - inc)].
            int kl = w->klat, ku = w->kuat, ld = w->ldat;
            int nbs = imax(w->klat, w->klbt); // nbs: near-boundary stencils
            SCALAR * at_j = w->A_T + kl; // For factorization-ready data
            at_j += ku*inc;
            ld -= inc;

            // The number of near-boundary schemes that need to be replaced
            // goes by the width of the stencil (widest side), in this case,
            // that of B_T
            for (int j = 0; j < nbs; at_j += ld, ++j) {

                // Start at j - ku, go down to 1
                for (int joff = w->kuat; joff > 0; --joff) {
                    at_j[(j-joff)*inc] = 0;
                }
                // Diagonal element
                at_j[(j  )*inc] = 1;
                // Start at 1, go to j + kl
                for (int joff = 1; joff < w->klat+1; ++joff) {
                    at_j[(j+joff)*inc] = 0;
                }
            }
        }
        break;

    case SUZERAIN_FILTEROP_BOUNDARY_SYMMETRY:
        // Replace near-boundary schemes on B^T
        {
            // Banded matrix access has form a[(ku+i)*inc + j*(lda-inc)].
            // Incorporate the ku offset and decrement ld to speed indexing
            int ku = w->kubt, ld = w->ldbt;
            SCALAR * bt_j  = w->B_T;
            bt_j += ku*inc;
            ld -= inc;

            for (int j = 0; j < w->kubt; bt_j += ld, ++j) {

                // Boundary element is bt_j[0];
                for (int joff = 1; joff < w->kubt+1-j; ++joff) {
                    // Consider f(-joff) = 2*f(0) - f(joff)
                    bt_j[(0     )*inc] += 2*bt_j[(0-joff)*inc];
                    bt_j[(0+joff)*inc] -=   bt_j[(0-joff)*inc];
                    // Reset value at ghost element
                    bt_j[(0-joff)*inc]  = 0;
                }
            }
        }

        // Replace near-boundary schemes on A^T
        {
            // Again, access has form a[(ku + i)*inc + j*(lda - inc)].
            int kl = w->klat, ku = w->kuat, ld = w->ldat;
            SCALAR * at_j = w->A_T + kl; // For factorization-ready data
            at_j += ku*inc;
            ld -= inc;

            // The number of near-boundary schemes that need to be replaced
            // goes in general by the width of the stencil (widest side).
            // In the symmetry case, however, the only rows that change
            // in A_T are those with coefficients of A_T at ghost points.
            for (int j = 0; j < w->kuat; at_j += ld, ++j) {

                // Boundary element is at_j[0];
                for (int joff = 1; joff < w->kuat+1-j; ++joff) {
                    // Consider f(-joff) = 2*f(0) - f(joff)
                    at_j[(0     )*inc] += 2*at_j[(0-joff)*inc];
                    at_j[(0+joff)*inc] -=   at_j[(0-joff)*inc];
                    // Reset value at ghost element
                    at_j[(0-joff)*inc]  = 0;
                }
            }
        }
        break;

    case SUZERAIN_FILTEROP_BOUNDARY_PERIODIC: // TODO
    default:
        SUZERAIN_ERROR_NULL("Unknown first boundary treatment",
                            SUZERAIN_ESANITY);
    }

    switch (w->b_last) {
    case SUZERAIN_FILTEROP_BOUNDARY_IGNORE:
        /* Nothing to be done */
        break;

    case SUZERAIN_FILTEROP_BOUNDARY_NOFILTER:
        // Replace near-boundary schemes on B^T
        {
            // Banded matrix access has form a[(ku+i)*inc + j*(lda-inc)].
            // Incorporate the ku offset and decrement ld to speed indexing.
            int ku = w->kubt, ld = w->ldbt;
            int nbs = imax(w->klat, w->klbt); // nbs: near-boundary stencils
            SCALAR * bt_j = w->B_T;

            // Walk the upper end forwards:
            // Point initially to element (n-nbs) in the diagonal
            bt_j += (ku*inc + (n-nbs)*(w->ldbt)*inc);
            ld -= inc;

            // Walk the matrix forwards
            for (int j = 0; j < nbs; bt_j += ld, ++j) {

                // Start at j - ku, go down to 1
                for (int joff = w->kubt; joff > 0; --joff) {
                    bt_j[(j-joff)*inc] = 0;
                }
                // Diagonal element
                bt_j[(j  )*inc] = 1;
                // Start at 1, go to j + kl
                for (int joff = 1; joff < w->klbt+1; ++joff) {
                    bt_j[(j+joff)*inc] = 0;
                }
            }

            // Note: To walk the upper end backwards instead, the initial
            // bt_j offset points initially to the last diagonal element,
            // as
            //     bt_j += (ku*inc + (n-1)*(w->ldbt)*inc);
            // and the outer loop changes to
            //     for (int j = 0; j > -nbs; bt_j -= ld, --j) { ... }

        }

        // Replace near-boundary schemes on A^T
        {
            // Again, access has form a[(ku + i)*inc + j*(lda - inc)].
            int kl = w->klat, ku = w->kuat, ld = w->ldat;
            int nbs = imax(w->klat, w->klbt); // nbs: near-boundary stencils
            SCALAR * at_j = w->A_T + kl; // For factorization-ready data

            // Walk the upper end forwards:
            // Point initially to element (n-nbs) in the diagonal
            at_j += (ku*inc + (n-nbs)*(w->ldat)*inc);
            ld -= inc;

            // Walk the matrix forwards
            for (int j = 0; j < nbs; at_j += ld, ++j) {

                // Start at j - ku, go down to 1
                for (int joff = w->kuat; joff > 0; --joff) {
                    at_j[(j-joff)*inc] = 0;
                }
                // Diagonal element
                at_j[(j  )*inc] = 1;
                // Start at 1, go to j + kl
                for (int joff = 1; joff < w->klat+1; ++joff) {
                    at_j[(j+joff)*inc] = 0;
                }
            }

            // Note: To walk the upper end backwards instead, the initial
            // at_j offset points initially to the last diagonal element,
            // as
            //     at_j += (ku*inc + (n-1)*(w->ldat)*inc);
            // and the outer loop changes to
            //     for (int j = 0; j > -nbs; at_j -= ld, --j) { ... }
        }
        break;

    case SUZERAIN_FILTEROP_BOUNDARY_SYMMETRY:
        // Replace near-boundary schemes on B^T
        {
            // Banded matrix access has form a[(ku+i)*inc + j*(lda-inc)].
            // Incorporate the ku offset and decrement ld to speed indexing
            int ku = w->kubt, ld = w->ldbt;
            SCALAR * bt_j  = w->B_T;

            // Walk the upper end backwards
            // Point initially to element (n-1) in the diagonal
            bt_j += (ku*inc + (n-1)*(w->ldbt)*inc);
            ld -= inc;

            for (int j = 0; j > -w->klbt; bt_j -= ld, --j) {

                // Boundary element is bt_j[0]
                for (int joff = 1; joff < (w->klbt)+1+j; ++joff) {
                    // Consider f(n-1+joff) = 2*f(n-1) - f(n-1-joff)
                    bt_j[(0     )*inc] += 2*bt_j[(0+joff)*inc];
                    bt_j[(0-joff)*inc] -=   bt_j[(0+joff)*inc];
                    // Reset value at ghost element
                    bt_j[(0+joff)*inc]  = 0;
                }
            }
        }


        // Replace near-boundary schemes on A^T
        {
            // Again, access has form a[(ku + i)*inc + j*(lda - inc)].
            int kl = w->klat, ku = w->kuat, ld = w->ldat;
            SCALAR * at_j = w->A_T + kl; // For factorization-ready data

            // Walk the upper end backwards
            // Point initially to element (n-1) in the diagonal
            at_j += (ku*inc + (n-1)*(w->ldat)*inc);
            ld -= inc;

            // The number of near-boundary schemes that need to be replaced
            // goes in general by the width of the stencil (widest side).
            // In the symmetry case, however, the only rows that change
            // in A_T are those with coefficients of A_T at ghost points.
            for (int j = 0; j > -(w->klat); at_j -= ld, --j) {

                // Boundary element is at_j[0];
                for (int joff = 1; joff < (w->klat)+1+j; ++joff) {
                    // Consider f(n-1+joff) = 2*f(n-1) - f(n-1-joff)
                    at_j[(0     )*inc] += 2*at_j[(0+joff)*inc];
                    at_j[(0-joff)*inc] -=   at_j[(0+joff)*inc];
                    // Reset value at ghost element
                    at_j[(0+joff)*inc]  = 0;
                }
            }
        }
        break;

    case SUZERAIN_FILTEROP_BOUNDARY_PERIODIC: // TODO
    default:
        SUZERAIN_ERROR_NULL("Unknown last boundary treatment",
                            SUZERAIN_ESANITY);
    }

    return retval;
}

WORK(suzerain_filterop,_workspace) *
WORK(suzerain_filterop,_alloc)(
    const int n,
    const enum suzerain_filterop_method method,
    const SCALAR *method_params,
    const enum suzerain_filterop_boundary_treatment b_first,
    const enum suzerain_filterop_boundary_treatment b_last)
{
    /* Parameter sanity checks */
    if (n < 1) {
        SUZERAIN_ERROR_NULL("n must be strictly positive", SUZERAIN_EINVAL);
    }

    /* Compute bandwidth-related information before allocating workspace */
    int klat, kuat, ldat;
    int klbt, kubt, ldbt;
    if (SUZERAIN_SUCCESS != WORK(suzerain_filterop,_operator_bandwidths)(method,
                method_params, &klat, &kuat, &ldat, &klbt, &kubt, &ldbt)) {
        SUZERAIN_ERROR_NULL("Unable to compute bandwidths for method",
                            SUZERAIN_EFAILED);
    }

    /* Allocate space for the workspace struct and initialize to zero */
    WORK(suzerain_filterop,_workspace) * const w
            = calloc(1, sizeof(WORK(suzerain_filterop,_workspace)));
    if (w == NULL) {
        SUZERAIN_ERROR_NULL("failed to allocate space for workspace",
                            SUZERAIN_ENOMEM);
    }

    /* Populate initial workspace values */
    w->method  = method;
    w->b_first = b_first;
    w->b_last  = b_last;
    w->n       = n;
    w->klat    = klat;
    w->kuat    = kuat;
    w->ldat    = ldat;
    w->klbt    = klbt;
    w->kubt    = kubt;
    w->ldbt    = ldbt;

    /* Allocate one contiguous block for B and A, in that order */
    w->B_T = suzerain_blas_calloc((w->n * w->ldbt) + (w->n * w->ldat),
                                  sizeof(w->B_T[0]));
    if (w->B_T == NULL) {
        WORK(suzerain_filterop,_free)(w);
        SUZERAIN_ERROR_NULL("failed to allocate space for B_T and A_T",
                            SUZERAIN_ENOMEM);
    }
    w->A_T = w->B_T + (w->n * w->ldbt);

    /* Allocate space for the pivot vector for A_T's factorization */
    w->ipiva = suzerain_blas_calloc(w->n, sizeof(w->ipiva[0]));
    if (w->ipiva == NULL) {
        WORK(suzerain_filterop,_free)(w);
        SUZERAIN_ERROR_NULL("failed to allocate space for ipiva",
                            SUZERAIN_ENOMEM);
    }

    /* Initialize A_T and B_T depending on the method */
    if (SUZERAIN_SUCCESS != WORK(suzerain_filterop,_operator_assemble)(
                method_params, w)) {
        WORK(suzerain_filterop,_free)(w);
        SUZERAIN_ERROR_NULL("failed to assemble A_T and B_T",
                            SUZERAIN_EFAILED);
    }

    /* Apply chosen boundary treatment */
    if (SUZERAIN_SUCCESS != WORK(suzerain_filterop,_operator_boundaries)(w)) {
        WORK(suzerain_filterop,_free)(w);
        SUZERAIN_ERROR_NULL("failed to modify A_T and B_T for boundaries",
                            SUZERAIN_EFAILED);
    }

    return w;
}

void
WORK(suzerain_filterop,_free)(
    WORK(suzerain_filterop,_workspace) *w)
{
    if (w) {
        // B_T and A_T were allocated as a single block, so just one free
        w->A_T = NULL;
        suzerain_blas_free(w->B_T);
        w->B_T = NULL;
        suzerain_blas_free(w->ipiva);
        w->ipiva = NULL;
    }
    free(w);
}

int
WORK(suzerain_filterop,_factorize)(
    WORK(suzerain_filterop,_workspace) *w)
{
    /* Protect the user from incorrect API usage */
    if (w->ipiva[0] > 0) {
        SUZERAIN_ERROR("Unable to factor an already-factored operator",
                       SUZERAIN_EINVAL);
    }

    /* Compute in-place LU factorization of the operator */
    const int info = BLAS(suzerain_lapack_,gbtrf)(w->n, w->n, w->klat, w->kuat,
                                                  w->A_T, w->ldat, w->ipiva);
    if (info) {
        char buffer[80];
        snprintf(buffer, sizeof(buffer),
                 STRINGIFY(BLAS(suzerain_lapack_,gbtrf))
                 " reported error %d", info);
        SUZERAIN_ERROR(buffer, SUZERAIN_ESANITY);
    }

    /* Factorization overwrote w->ipiv[0] with something nonnegative;
     * This is our flag to check that factorization indeed occurred */

    return SUZERAIN_SUCCESS;
}

int
WORK(suzerain_filterop,_apply)(
    const SCALAR alpha,
    const SCALAR *x,
    const int incx,
    SCALAR *y,
    const int incy,
    const WORK(suzerain_filterop,_workspace) *w)
{
    // TODO Periodic boundary treatments require additional processing

    return BLAS(suzerain_blas_,gbmv)('T', w->n, w->n, w->klbt, w->kubt,
                                     alpha, w->B_T, w->ldbt, x, incx,
                                     /* overwrite */ 0,      y, incy);
}

int
WORK(suzerain_filterop,_solve)(
    const int nrhs,
    SCALAR *X,
    const int ldx,
    const WORK(suzerain_filterop,_workspace) * w)
{
    // TODO Periodic boundary treatments require additional processing

    if (w->ipiva[0] <= 0) {
        SUZERAIN_ERROR(STRINGIFY(WORK(suzerain_filterop,_factorize))
                       " not called before solve", SUZERAIN_EINVAL);
    }

    const int info = BLAS(suzerain_lapack_,gbtrs)('T', w->n, w->klat, w->kuat,
                                                  nrhs, w->A_T, w->ldat,
                                                  w->ipiva, X, ldx);
    if (info) {
        char buffer[80];
        snprintf(buffer, sizeof(buffer),
                 STRINGIFY(BLAS(suzerain_lapack_,gbtrs))
                 " reported error %d", info);
        SUZERAIN_ERROR(buffer, SUZERAIN_ESANITY);
    }

    return SUZERAIN_SUCCESS;
}

int
WORK(suzerain_filterop,_filter)(
    const SCALAR alpha,
    const SCALAR *x,
    const int incx,
    SCALAR *y,
    const WORK(suzerain_filterop,_workspace) *w)
{
    int info;

    /* Apply B operator out-of-place */
    info = WORK(suzerain_filterop,_apply)(alpha, x, incx,
                                          y, /* contiguous */ 1, w);
    if (info) return info;

    info = WORK(suzerain_filterop,_solve)(/* one vector */ 1, y, w->n, w);

    return info;
}

#undef STRINGIFY_HELPER
#undef STRINGIFY

#undef SCALAR
#undef BLAS
#undef WORK

/* vim: set ft=c:   */
/* Local Variables: */
/* mode: c          */
/* End:             */
