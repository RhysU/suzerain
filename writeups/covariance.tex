\documentclass[letterpaper,11pt,nointlimits,reqno]{amsart}

% Packages
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{fullpage}
\usepackage{lastpage}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{parskip}
\usepackage{setspace}
\usepackage{txfonts}
\usepackage{varioref}

% Hyperref package must be last otherwise the contents are jumbled
% hypertexnames disabled to fix links pointing to incorrect locations
\usepackage[hypertexnames=false,final]{hyperref}

\mathtoolsset{showonlyrefs,showmanualtags}
\allowdisplaybreaks[1] % Allow grouped equations to be split across pages

% Line Spacing
\singlespacing

% Set appropriate header/footer information on each page
\fancypagestyle{plain}{
    \fancyhf{}
    \renewcommand{\headheight}{2.0em}
    \renewcommand{\headsep}{0.75em}
    \renewcommand{\headrulewidth}{1.0pt}
    \renewcommand{\footrulewidth}{0pt}
    \lhead{
        A covariance estimation procedure for nonuniformly
        sampled, autocorrelated processes.
    }
    \rhead{
        Page \thepage{} of \pageref{LastPage}
    }
}
\pagestyle{plain}

% Document-specific commands
\newcommand{\trans}[1]{{#1}^{\ensuremath{\mathsf{T}}}}
\newcommand{\OO}[1]{\operatorname{O}\left(#1\right)}
\DeclareMathOperator{\cov}{cov}

\begin{document}

\subsection*{Problem}

Assume the existence of two stationary, real-valued stochastic processes
$\vec{\mathscr{X}}$ and $\vec{\mathscr{Y}}$ with finite, but unknown and
possibly distinct, first and second moments and decaying, but unknown and
possibly distinct, autocorrelations.  Estimate
$\cov\left(\vec{\mathscr{X}},\vec{\mathscr{Y}}\right)$ given two realization
sequences $\vec{x}\left(t_i\right)$ and $\vec{y}\left(t_i\right)$ for
$i\in\left\{0,1,\dots,N-1\right\}$ where $t_i < t_{i+1}$.  Further, when
$\mathscr{X}=\mathscr{Y}$, estimate the variance of the sample mean in a
consistent manner.

\subsection*{Assumptions}

Assume that $t$ is appreciably larger than the decay time of the
autocorrelation of both processes and that $I$ ``covers $\left[0,t\right)$
well-enough'' that interrogating $\alpha N$ consecutive samples when
$\alpha<1/2$ will provide adequate autocorrelation information without running
afoul of the Nyquist sampling criterion.  $N$ must be large enough that
standard estimates of $\operatorname{E}\left[\vec{\mathscr{X}}\right]$ and
$\operatorname{E}\left[\vec{\mathscr{Y}}\right]$ may be taken as known means
without incurring too much bias as Percival~\cite{Percival1993Three} suggests
they might.  All-in-all, these imprecise restrictions are meant to suggest that
$\vec{x}_i$ and $\vec{y}_i$ are in situ samples from a converged, turbulence
simulation.  The nonuniform sampling is intended to account for possibly
missing samples or sample time drift across a long-running simulation.  For
now, efficiency of the procedure is a secondary concern.

\subsection*{Approach}

The estimation process proceeds in five steps.  First, construct uniform
temporal samples $\vec{X}$ and $\vec{Y}$ from the nonuniform $\vec{x}$ and
$\vec{y}$ via a discrete Fourier transform-based projection.  Second, estimate
the cross-spectra of $\vec{X}$ and $\vec{Y}$ following
Welch~\cite{Welch1967Use} to maximally reduce the variance of these estimates
given limited data.  Next, compute the projected covariances from the
cross-spectra estimates obtaining an ``effective sample size'' along the way
per recommendations by Thi\'{e}baux and
Zwiers~\cite{Thiebaux1984Interpretation}.  Then, compute the covariances
corresponding to the original $\vec{x}$ and $\vec{y}$ using the linearity of
the projection.  Finally, when $\mathscr{X}=\mathscr{Y}$, estimate the variance
of the sample mean in a consistent manner.

\subsection*{Projection onto uniform temporal samples}

Set $t_0=0$ without loss of generality and define
$$
T = \frac{t_{N-1} N}{N-1}.
$$
$T$ will be the sampling window for a non-uniform discrete transform (NDFT).
It was chosen so that a subsequent uniform, inverse discrete Fourier transform
(IDFT) will exactly recover $\vec{X}=\vec{x}$ when $\vec{x}$ was sampled
uniformly in time.  The temporal projection performs an NDFT followed by an
IDFT to produce $N$ uniform samples $\vec{X}\left(2\pi{}i/N\right)$ from the
original $\vec{x}\left(t_k\right)$.  $\vec{Y}$ is constructed identically from
$\vec{y}$.

The projection $A$ operates separately on each element $x$ of $\vec{x}$
to produce each element $X$ of $\vec{X}$ according to
$$
    X\left(2\pi{}i/N\right)
    =
    A_{ik} x\left(t_k\right)
    =
    \frac{1}{N}
    \sum_{j=0}^{N-1} \exp\left(\frac{ 2\pi\sqrt{-1} i j   }{N} \right)
    \sum_{k=0}^{N-1} \exp\left(\frac{-2\pi\sqrt{-1} j t_k }{T} \right)
    x\left(t_k\right)
.
$$
As $t_k$ are not known here, the usual discrete orthogonality relations are not
used to simplify $A$.  Fast algorithms may be used to compute the NDFT but will
incur more floating point error than the naive NDFT (e.g. see Kunis and
Potts~\cite{Kunis2008Time}).  The fast Fourier transform may be used to compute
the IDFT.  Hermitian symmetry can be used to reduce the cost of both
transforms.

\subsection*{Cross-spectra estimation from the uniform samples}

An estimate of the cross-spectra $\hat{P}$ is computed for each pair in
$\left(\vec{X} - \operatorname{E}\left[\vec{X}\right]\right) \otimes
\left(\vec{Y} - \operatorname{E}\left[\vec{Y}\right]\right)$ using Welch's
approach~\cite{Welch1967Use}.  Only $\hat{P}(0)$ is of interest here.  Notice
the variance of $\hat{P}(0)$ will be twice that of the rest of $\hat{P}$
as Welch describes.

Procedurally, Welch's averaging segment length $L$ should be taken as
$\alpha{}N$ for some $\alpha<1/2$.  A fraction of $N$ is chosen the
$N\to\infty$ limit might behave reasonably (as mentioned by Thi\'{e}baux and
Zwiers~\cite{Thiebaux1984Interpretation}, p. 803).  To get a near maximum
reduction in the covariance from a fixed number of samples, the segments should
be overlapped by one half their length (i.e.  $D = L / 2 = \alpha{}N$).  The
spectral window that Welch denotes $W_1$ is suggested though with adequate data
using either $W_1$ or $W_2$ should give comparable results.

The free parameter $\alpha$ plays a role similar to the ``coarse-graining''
within the variance estimation procedure described in the appendix of Hoyas and
Jim\'{e}nez~\cite{Hoyas2008Reynolds}.  When applied to adequate data it is
expected that Welch's procedure as $\alpha\to{}1/2$ will also converge to a
single result.  With Welch's overlapping window technique it should be possible
to glean more information from fixed data than the approach Hoyas and
Jim\'{e}nez propose.

\subsection*{Covariance computation from cross-spectra estimates}

TODO

\subsection*{Reverse projection of the covariances}

TODO

\subsection*{Checking stationarity}

Small changes to the periodogram averaging segment size $\alpha N$
should cause small perturbations to the results when $N$ is sufficiently
large and $t_i$ are sufficiently distributed.

This procedure should be amenable to applying the Geweke
diagnostic~\cite{Geweke1992Evaluating} as a way to assess convergence.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%% Bibliography %%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{amsplain}
\bibliography{references}

\end{document}
