#!/bin/bash
#############################################################################
# Template for generated, generic job submission script in SLURM
# Production-ready jobscripts are installed in $prefix/jobscripts
#
# using: 
# https://computing.llnl.gov/linux/slurm/quickstart.html
# https://computing.llnl.gov/tutorials/lc_resources/
# https://computing.llnl.gov/?set=resources&page=OCF_resources#cab
#############################################################################
#
#SBATCH -J suzerain           # Job name
#SBATCH -o myjob.%j.out       # stdout; %j expands to jobid
#SBATCH -e myjob.%j.err       # stderr; skip to combine stdout and stderr

# FIXME
##$ -pe @corespernode@way @corespernode@          # Requests TpN tasks/node, (NoN x @corespernode@) cores total
#SBATCH -N 2 # Number of nodes, not cores (16 cores/node)
#SBATCH -n 32 # Total number of MPI tasks (if omitted, n=N)

#SBATCH -p normal # queue name
#SBATCH -t 00:30:00 # max tim

#$ -notify               # Notify job of impending doom
set -m                   # Employ job control
set -u                   # Abort on undefined shell variables
unset DISPLAY            # Avoid "Error in locking authority file" from xauth

# Either obtain the soft run time or compute default from hard run time
RESOURCE_LIST=$(qstat -j $JOB_ID | grep resource_list)
H_RT=$(echo $RESOURCE_LIST | egrep -o 'h_rt=[0-9]+*' | egrep -o '[0-9]+')
S_RT=$(echo $RESOURCE_LIST | egrep -o 's_rt=[0-9]+*' | egrep -o '[0-9]+')
test -z "$S_RT" && S_RT=$(expr $H_RT - 60)
test "${S_RT:=0}" -lt 0 && S_RT=0

# Provide defaults for environment variables used to build CMD (see below).
# Rather than editing this job submission script, modify your environment!
# Even after job submission, 'qalter -v' can modify a job's environment.
: ${BINARY=@bindir@/perfect_advance}
: ${INPUT=@pkgdatadir@/fields/channel_k08.h5}  # Use SCRATCH or WORK
: ${ADVANCE=}
: ${STATUS=}
: ${DECOMP=--Pa=$(expr $NSLOTS / $NHOSTS)}
: ${OPTIONS=}
: ${PLANNING=--plan_wisdom=$HOME/.wisdom --rigor_fft=patient}
: ${CHEMFILE=}
: ${TMPFILES=--metadata=metadata.h5.$JOB_ID --uncommitted=uncommitted.h5.$JOB_ID}
: ${JOBDIR=$SCRATCH/jobs/$JOB_NAME/$JOB_ID}

# Make job directory, canonicalize paths, and build command
mkdir -p "$JOBDIR"
function canonpath() { echo $(cd $(dirname "$1"); pwd -P)/$(basename "$1") ; }
BINARY=$(canonpath "$BINARY")
INPUT=$(canonpath "$INPUT")
JOBDIR=$(canonpath "$JOBDIR")
test -n "$CHEMFILE" && CHEMFILE=$(canonpath "$CHEMFILE")
cd "$JOBDIR"
# Copy any non-{SCRATCH,WORK} INPUT to JOBDIR to employ parallel filesystem
# Expensive for large fields but users should not be keeping those in $HOME
case "$INPUT" in                                                         #(
    ${SCRATCH}*) :
                 ;;                                                      #(
    ${WORK}*)    :
                 ;;                                                      #(
    *)           MSGS="${MSGS-}$(cp -v "$INPUT" "$JOBDIR/input.h5")$(echo)"
                 INPUT=$(canonpath "$JOBDIR/input.h5")
                 ;;
esac
# If JOBDIR ends with JOB_ID, add or overwrite '../last' for postprocessing
case "$JOBDIR" in                                                        #(
    */${JOB_ID}) ln -f -n -s "$JOB_ID" ../last
                 ;;
esac
# If supplied, copy CHEMFILE to JOBDIR and modify OPTIONS to provide it
if test -n "$CHEMFILE"; then
    if test -f "$CHEMFILE"; then
        MSGS="${MSGS-}Added copy of CHEMFILE to OPTIONS$(echo)"
        MSGS="${MSGS-}$(cp -v "$CHEMFILE" .)$(echo)"
        OPTIONS="$OPTIONS --chemfile=$(basename "$CHEMFILE")"
    else
        MSGS="${MSGS-}WARN: CHEMFILE unused as it is a non-file path$(echo)"
    fi
fi
CMD="\"$BINARY\" \"$INPUT\" $ADVANCE --advance_wt=$S_RT $STATUS $DECOMP $PLANNING $TMPFILES $OPTIONS"

# Compute threading based on job size and way-ness
export OMP_NUM_THREADS=$(expr @corespernode@ / \( $NSLOTS / $NHOSTS \) )

# Record execution details into working directory
exec 1> >(tee ./output) 2>&1
echo "$BINARY" > ./binary
"$BINARY" --version > ./version
ldd "$BINARY" > ./dependencies
env > ./environment
test -f /proc/version && cp /proc/version ./kernel  && chmod +w ./kernel
test -f /proc/meminfo && cp /proc/meminfo ./meminfo && chmod +w ./meminfo
test -f /proc/cpuinfo && cp /proc/cpuinfo ./cpuinfo && chmod +w ./cpuinfo

# Display a job header
cat <<HEADER
=${JOB_NAME}=${JOB_ID}=========================================================
CLUSTER:  $SGE_CLUSTER_NAME ${PE-} $NSLOTS
JOB_ID:   $JOB_ID
DATE:     $(date)
JOBDIR:   $JOBDIR
STDOUT:   $SGE_STDOUT_PATH
H_RT:     $H_RT

BINARY:   $BINARY
INPUT:    $INPUT
ADVANCE:  $ADVANCE
S_RT:     $S_RT
STATUS:   $STATUS
DECOMP:   $DECOMP
OPTIONS:  $OPTIONS
PLANNING: $PLANNING
CHEMFILE: $CHEMFILE
TMPFILES: $TMPFILES

${MSGS:-}${MSGS:+
}${CMD}
=${JOB_NAME}=${JOB_ID}=========================================================

HEADER

# Execute the command, passing along any signals, and wait for completion
cache_binary "$PWD" "$BINARY"
/usr/bin/time -v srun $CMD &
CMDPID=$!
for signal in ${SIGNALS=HUP INT TERM USR1 USR2}; do
    trap "kill -s $signal $CMDPID" $signal
done
fg
CMDEXIT=$?
for signal in ${SIGNALS}; do
    trap - $signal
done

# Mail output to the job submitter.  Sleep required for message receipt.
mail -s "Job $JOB_ID ($JOB_NAME) Output [$CMDEXIT]" $USER < ./output && sleep 10

# Sun Grid Engine blocks any dependent (-hold_jid) jobs on exit 100,
# so coerce CMDEXIT to be either 0 if we succeeded or 100 if we failed.
if [ "$CMDEXIT" = 0 ]; then
    exit 0
else
    exit 100
fi
